{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCjrHEtzh5EQ"
      },
      "source": [
        "https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/facebookresearch_pytorchvideo_slowfast.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6FAJn6iv8Pf"
      },
      "source": [
        "https://github.com/wufan-tb/yolo_slowfast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHL5rGbTg9JN",
        "outputId": "85e0fa59-fd11-4b1b-ca82-08ffa8510f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.12/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (6.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (3.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fvcore) (11.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from iopath>=0.1.7->fvcore) (4.15.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from iopath>=0.1.7->fvcore) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdFjT2T3g-nR",
        "outputId": "c92b5b87-dbe7-46c4-d8b5-8488b3d8954a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (16.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install av"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rHlcoYbdwIs_"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-DyHdy_hoIcv"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT-Lg9URhHHz",
        "outputId": "fe5216a9-fa76-4c11-a6a6-5049ccc6992b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        }
      ],
      "source": [
        "sf_model = torch.hub.load(\n",
        "    'facebookresearch/pytorchvideo',\n",
        "    'slowfast_r50',\n",
        "    pretrained=True\n",
        ").eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgxmarwOhHlQ",
        "outputId": "8b10dc66-48d5-4edb-b939-4d9291511dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict\n",
        "import json\n",
        "import urllib\n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Zg28Im1ZHHXm"
      },
      "outputs": [],
      "source": [
        "json_url = \"https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\"\n",
        "json_filename = \"kinetics_classnames.json\"\n",
        "\n",
        "try: urllib.URLopener().retrieve(json_url, json_filename)\n",
        "except: urllib.request.urlretrieve(json_url, json_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1GZN7lGeVtMG",
        "outputId": "d8821c9b-d855-4121-9189-ae3ff17a497e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{290: 'sharpening knives',\n",
              " 115: 'eating ice cream',\n",
              " 81: 'cutting nails',\n",
              " 53: 'changing wheel',\n",
              " 19: 'bench pressing',\n",
              " 88: 'deadlifting',\n",
              " 111: 'eating carrots',\n",
              " 192: 'marching',\n",
              " 358: 'throwing discus',\n",
              " 231: 'playing flute',\n",
              " 72: 'cooking on campfire',\n",
              " 33: 'breading or breadcrumbing',\n",
              " 218: 'playing badminton',\n",
              " 276: 'ripping paper',\n",
              " 244: 'playing saxophone',\n",
              " 197: 'milking cow',\n",
              " 169: 'juggling balls',\n",
              " 130: 'flying kite',\n",
              " 43: 'capoeira',\n",
              " 187: 'making jewelry',\n",
              " 100: 'drinking',\n",
              " 228: 'playing cymbals',\n",
              " 61: 'cleaning gutters',\n",
              " 161: 'hurling (sport)',\n",
              " 239: 'playing organ',\n",
              " 361: 'tossing coin',\n",
              " 395: 'wrestling',\n",
              " 103: 'driving car',\n",
              " 150: 'headbutting',\n",
              " 147: 'gymnastics tumbling',\n",
              " 186: 'making bed',\n",
              " 0: 'abseiling',\n",
              " 155: 'holding snake',\n",
              " 278: 'rock climbing',\n",
              " 71: 'cooking egg',\n",
              " 182: 'long jump',\n",
              " 17: 'bee keeping',\n",
              " 365: 'trimming or shaving beard',\n",
              " 63: 'cleaning shoes',\n",
              " 86: 'dancing gangnam style',\n",
              " 50: 'catching or throwing softball',\n",
              " 164: 'ice skating',\n",
              " 168: 'jogging',\n",
              " 116: 'eating spaghetti',\n",
              " 28: 'bobsledding',\n",
              " 8: 'assembling computer',\n",
              " 227: 'playing cricket',\n",
              " 238: 'playing monopoly',\n",
              " 143: 'golf putting',\n",
              " 188: 'making pizza',\n",
              " 166: 'javelin throw',\n",
              " 211: 'peeling potatoes',\n",
              " 57: 'clapping',\n",
              " 36: 'brushing hair',\n",
              " 129: 'flipping pancake',\n",
              " 101: 'drinking beer',\n",
              " 99: 'dribbling basketball',\n",
              " 219: 'playing bagpipes',\n",
              " 325: 'somersaulting',\n",
              " 42: 'canoeing or kayaking',\n",
              " 275: 'riding unicycle',\n",
              " 355: 'texting',\n",
              " 352: 'tasting beer',\n",
              " 154: 'hockey stop',\n",
              " 225: 'playing clarinet',\n",
              " 389: 'waxing legs',\n",
              " 80: 'curling hair',\n",
              " 281: 'running on treadmill',\n",
              " 346: 'tai chi',\n",
              " 104: 'driving tractor',\n",
              " 293: 'shaving legs',\n",
              " 291: 'sharpening pencil',\n",
              " 190: 'making sushi',\n",
              " 327: 'spray painting',\n",
              " 305: 'situp',\n",
              " 237: 'playing kickball',\n",
              " 331: 'sticking tongue out',\n",
              " 149: 'headbanging',\n",
              " 132: 'folding napkins',\n",
              " 241: 'playing piano',\n",
              " 312: 'skydiving',\n",
              " 85: 'dancing charleston',\n",
              " 163: 'ice fishing',\n",
              " 359: 'tickling',\n",
              " 13: 'bandaging',\n",
              " 151: 'high jump',\n",
              " 185: 'making a sandwich',\n",
              " 271: 'riding mountain bike',\n",
              " 82: 'cutting pineapple',\n",
              " 125: 'feeding goats',\n",
              " 87: 'dancing macarena',\n",
              " 220: 'playing basketball',\n",
              " 179: 'krumping',\n",
              " 152: 'high kick',\n",
              " 12: 'balloon blowing',\n",
              " 217: 'playing accordion',\n",
              " 224: 'playing chess',\n",
              " 159: 'hula hooping',\n",
              " 263: 'pushing wheelchair',\n",
              " 268: 'riding camel',\n",
              " 27: 'blowing out candles',\n",
              " 121: 'extinguishing fire',\n",
              " 373: 'using computer',\n",
              " 173: 'jumpstyle dancing',\n",
              " 397: 'yawning',\n",
              " 396: 'writing',\n",
              " 172: 'jumping into pool',\n",
              " 96: 'doing laundry',\n",
              " 118: 'egg hunting',\n",
              " 284: 'sanding floor',\n",
              " 200: 'moving furniture',\n",
              " 119: 'exercising arm',\n",
              " 345: 'sword fighting',\n",
              " 303: 'sign language interpreting',\n",
              " 74: 'counting money',\n",
              " 15: 'bartending',\n",
              " 65: 'cleaning windows',\n",
              " 23: 'blasting sand',\n",
              " 213: 'petting cat',\n",
              " 320: 'sniffing',\n",
              " 31: 'bowling',\n",
              " 242: 'playing poker',\n",
              " 347: 'taking a shower',\n",
              " 382: 'washing hands',\n",
              " 384: 'water sliding',\n",
              " 254: 'presenting weather forecast',\n",
              " 360: 'tobogganing',\n",
              " 51: 'celebrating',\n",
              " 138: 'getting a haircut',\n",
              " 321: 'snorkeling',\n",
              " 390: 'weaving basket',\n",
              " 245: 'playing squash or racquetball',\n",
              " 206: 'parasailing',\n",
              " 202: 'news anchoring',\n",
              " 18: 'belly dancing',\n",
              " 393: 'windsurfing',\n",
              " 32: 'braiding hair',\n",
              " 78: 'crossing river',\n",
              " 181: 'laying bricks',\n",
              " 280: 'roller skating',\n",
              " 156: 'hopscotch',\n",
              " 248: 'playing trumpet',\n",
              " 108: 'dying hair',\n",
              " 366: 'trimming trees',\n",
              " 256: 'pumping fist',\n",
              " 236: 'playing keyboard',\n",
              " 322: 'snowboarding',\n",
              " 136: 'garbage collecting',\n",
              " 226: 'playing controller',\n",
              " 94: 'dodgeball',\n",
              " 266: 'recording music',\n",
              " 75: 'country line dancing',\n",
              " 84: 'dancing ballet',\n",
              " 137: 'gargling',\n",
              " 165: 'ironing',\n",
              " 260: 'push up',\n",
              " 135: 'frying vegetables',\n",
              " 307: 'ski jumping',\n",
              " 201: 'mowing lawn',\n",
              " 139: 'getting a tattoo',\n",
              " 279: 'rock scissors paper',\n",
              " 55: 'cheerleading',\n",
              " 374: 'using remote controller (not gaming)',\n",
              " 289: 'shaking head',\n",
              " 282: 'sailing',\n",
              " 363: 'training dog',\n",
              " 160: 'hurdling',\n",
              " 128: 'fixing hair',\n",
              " 67: 'climbing ladder',\n",
              " 126: 'filling eyebrows',\n",
              " 329: 'springboard diving',\n",
              " 117: 'eating watermelon',\n",
              " 106: 'drumming fingers',\n",
              " 386: 'waxing back',\n",
              " 229: 'playing didgeridoo',\n",
              " 339: 'swimming backstroke',\n",
              " 22: 'biking through snow',\n",
              " 380: 'washing feet',\n",
              " 198: 'mopping floor',\n",
              " 357: 'throwing ball',\n",
              " 113: 'eating doughnuts',\n",
              " 102: 'drinking shots',\n",
              " 368: 'tying bow tie',\n",
              " 91: 'dining',\n",
              " 337: 'surfing water',\n",
              " 338: 'sweeping floor',\n",
              " 145: 'grooming dog',\n",
              " 47: 'catching fish',\n",
              " 257: 'pumping gas',\n",
              " 273: 'riding or walking with horse',\n",
              " 196: \"massaging person's head\",\n",
              " 5: 'archery',\n",
              " 162: 'ice climbing',\n",
              " 243: 'playing recorder',\n",
              " 89: 'decorating the christmas tree',\n",
              " 210: 'peeling apples',\n",
              " 324: 'snowmobiling',\n",
              " 249: 'playing ukulele',\n",
              " 109: 'eating burger',\n",
              " 38: 'building cabinet',\n",
              " 332: 'stomping grapes',\n",
              " 105: 'drop kicking',\n",
              " 209: 'passing American football (not in game)',\n",
              " 3: 'applauding',\n",
              " 158: 'hugging',\n",
              " 114: 'eating hotdog',\n",
              " 253: 'pole vault',\n",
              " 265: 'reading newspaper',\n",
              " 318: 'snatch weight lifting',\n",
              " 399: 'zumba',\n",
              " 235: 'playing ice hockey',\n",
              " 34: 'breakdancing',\n",
              " 124: 'feeding fish',\n",
              " 300: 'shredding paper',\n",
              " 49: 'catching or throwing frisbee',\n",
              " 120: 'exercising with an exercise ball',\n",
              " 262: 'pushing cart',\n",
              " 341: 'swimming butterfly stroke',\n",
              " 274: 'riding scooter',\n",
              " 328: 'spraying',\n",
              " 133: 'folding paper',\n",
              " 142: 'golf driving',\n",
              " 277: 'robot dancing',\n",
              " 20: 'bending back',\n",
              " 354: 'testifying',\n",
              " 387: 'waxing chest',\n",
              " 46: 'carving pumpkin',\n",
              " 153: 'hitting baseball',\n",
              " 269: 'riding elephant',\n",
              " 37: 'brushing teeth',\n",
              " 255: 'pull ups',\n",
              " 267: 'riding a bike',\n",
              " 306: 'skateboarding',\n",
              " 62: 'cleaning pool',\n",
              " 240: 'playing paintball',\n",
              " 193: 'massaging back',\n",
              " 299: 'shoveling snow',\n",
              " 336: 'surfing crowd',\n",
              " 371: 'unboxing',\n",
              " 122: 'faceplanting',\n",
              " 364: 'trapezing',\n",
              " 343: 'swinging legs',\n",
              " 157: 'hoverboarding',\n",
              " 250: 'playing violin',\n",
              " 394: 'wrapping present',\n",
              " 26: 'blowing nose',\n",
              " 174: 'kicking field goal',\n",
              " 214: 'picking fruit',\n",
              " 344: 'swinging on something',\n",
              " 140: 'giving or receiving award',\n",
              " 215: 'planting trees',\n",
              " 383: 'water skiing',\n",
              " 379: 'washing dishes',\n",
              " 258: 'punching bag',\n",
              " 195: 'massaging legs',\n",
              " 356: 'throwing axe',\n",
              " 283: 'salsa dancing',\n",
              " 29: 'bookbinding',\n",
              " 370: 'tying tie',\n",
              " 309: 'skiing crosscountry',\n",
              " 295: 'shining shoes',\n",
              " 189: 'making snowman',\n",
              " 134: 'front raises',\n",
              " 97: 'doing nails',\n",
              " 194: 'massaging feet',\n",
              " 230: 'playing drums',\n",
              " 316: 'smoking',\n",
              " 259: 'punching person (boxing)',\n",
              " 45: 'cartwheeling',\n",
              " 208: 'passing American football (in game)',\n",
              " 288: 'shaking hands',\n",
              " 216: 'plastering',\n",
              " 385: 'watering plants',\n",
              " 176: 'kissing',\n",
              " 314: 'slapping',\n",
              " 233: 'playing harmonica',\n",
              " 391: 'welding',\n",
              " 317: 'smoking hookah',\n",
              " 285: 'scrambling eggs',\n",
              " 70: 'cooking chicken',\n",
              " 261: 'pushing car',\n",
              " 203: 'opening bottle',\n",
              " 73: 'cooking sausages',\n",
              " 48: 'catching or throwing baseball',\n",
              " 340: 'swimming breast stroke',\n",
              " 90: 'digging',\n",
              " 252: 'playing xylophone',\n",
              " 95: 'doing aerobics',\n",
              " 247: 'playing trombone',\n",
              " 178: 'knitting',\n",
              " 377: 'waiting in line',\n",
              " 362: 'tossing salad',\n",
              " 330: 'squat',\n",
              " 376: 'vault',\n",
              " 375: 'using segway',\n",
              " 77: 'crawling baby',\n",
              " 264: 'reading book',\n",
              " 199: 'motorcycling',\n",
              " 14: 'barbequing',\n",
              " 60: 'cleaning floor',\n",
              " 223: 'playing cello',\n",
              " 98: 'drawing',\n",
              " 9: 'auctioning',\n",
              " 44: 'carrying baby',\n",
              " 93: 'diving cliff',\n",
              " 41: 'busking',\n",
              " 83: 'cutting watermelon',\n",
              " 286: 'scuba diving',\n",
              " 270: 'riding mechanical bull',\n",
              " 191: 'making tea',\n",
              " 246: 'playing tennis',\n",
              " 79: 'crying',\n",
              " 107: 'dunking basketball',\n",
              " 76: 'cracking neck',\n",
              " 7: 'arranging flowers',\n",
              " 39: 'building shed',\n",
              " 141: 'golf chipping',\n",
              " 353: 'tasting food',\n",
              " 292: 'shaving head',\n",
              " 2: 'answering questions',\n",
              " 68: 'climbing tree',\n",
              " 311: 'skipping rope',\n",
              " 177: 'kitesurfing',\n",
              " 170: 'juggling fire',\n",
              " 180: 'laughing',\n",
              " 205: 'paragliding',\n",
              " 69: 'contact juggling',\n",
              " 313: 'slacklining',\n",
              " 6: 'arm wrestling',\n",
              " 184: 'making a cake',\n",
              " 127: 'finger snapping',\n",
              " 146: 'grooming horse',\n",
              " 204: 'opening present',\n",
              " 351: 'tapping pen',\n",
              " 304: 'singing',\n",
              " 298: 'shot put',\n",
              " 64: 'cleaning toilet',\n",
              " 326: 'spinning poi',\n",
              " 287: 'setting table',\n",
              " 369: 'tying knot (not on a tie)',\n",
              " 24: 'blowing glass',\n",
              " 112: 'eating chips',\n",
              " 349: 'tap dancing',\n",
              " 66: 'climbing a rope',\n",
              " 35: 'brush painting',\n",
              " 56: 'chopping wood',\n",
              " 334: 'stretching leg',\n",
              " 212: 'petting animal (not cat)',\n",
              " 11: 'baking cookies',\n",
              " 333: 'stretching arm',\n",
              " 16: 'beatboxing',\n",
              " 167: 'jetskiing',\n",
              " 21: 'bending metal',\n",
              " 319: 'sneezing',\n",
              " 131: 'folding clothes',\n",
              " 315: 'sled dog racing',\n",
              " 350: 'tapping guitar',\n",
              " 30: 'bouncing on trampoline',\n",
              " 388: 'waxing eyebrows',\n",
              " 1: 'air drumming',\n",
              " 175: 'kicking soccer ball',\n",
              " 381: 'washing hair',\n",
              " 272: 'riding mule',\n",
              " 25: 'blowing leaves',\n",
              " 335: 'strumming guitar',\n",
              " 222: 'playing cards',\n",
              " 323: 'snowkiting',\n",
              " 221: 'playing bass guitar',\n",
              " 4: 'applying cream',\n",
              " 296: 'shooting basketball',\n",
              " 378: 'walking the dog',\n",
              " 367: 'triple jump',\n",
              " 294: 'shearing sheep',\n",
              " 58: 'clay pottery making',\n",
              " 40: 'bungee jumping',\n",
              " 372: 'unloading truck',\n",
              " 301: 'shuffling cards',\n",
              " 297: 'shooting goal (soccer)',\n",
              " 348: 'tango dancing',\n",
              " 302: 'side kick',\n",
              " 144: 'grinding meat',\n",
              " 398: 'yoga',\n",
              " 148: 'hammer throw',\n",
              " 52: 'changing oil',\n",
              " 54: 'checking tires',\n",
              " 207: 'parkour',\n",
              " 110: 'eating cake',\n",
              " 310: 'skiing slalom',\n",
              " 171: 'juggling soccer ball',\n",
              " 392: 'whistling',\n",
              " 123: 'feeding birds',\n",
              " 251: 'playing volleyball',\n",
              " 342: 'swing dancing',\n",
              " 308: 'skiing (not slalom or crosscountry)',\n",
              " 183: 'lunge',\n",
              " 92: 'disc golfing',\n",
              " 59: 'clean and jerk',\n",
              " 232: 'playing guitar',\n",
              " 10: 'baby waking up',\n",
              " 234: 'playing harp'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "with open(json_filename, \"r\") as f:\n",
        "    kinetics_classnames = json.load(f)\n",
        "\n",
        "kinetics_id_to_classname = {}\n",
        "for k, v in kinetics_classnames.items():\n",
        "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")\n",
        "\n",
        "kinetics_id_to_classname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "haqBQ81UVtCF"
      },
      "outputs": [],
      "source": [
        "side_size = 256\n",
        "mean = [0.45, 0.45, 0.45]\n",
        "std = [0.225, 0.225, 0.225]\n",
        "crop_size = 256\n",
        "num_frames = 32\n",
        "sampling_rate = 2\n",
        "frames_per_second = 30\n",
        "slowfast_alpha = 4\n",
        "num_clips = 10\n",
        "num_crops = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Pup0xG6NVs_O"
      },
      "outputs": [],
      "source": [
        "clip_duration = (num_frames * sampling_rate)/frames_per_second"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U1zn4LWNWRj9"
      },
      "outputs": [],
      "source": [
        "source_video_path = 'source_video.mp4'\n",
        "output_video_path = 'output_video.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4BgR14g0Vs8a"
      },
      "outputs": [],
      "source": [
        "class PackPathway(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Transform for converting video frames as a list of tensors.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, frames: torch.Tensor):\n",
        "        fast_pathway = frames\n",
        "        slow_pathway = torch.index_select(\n",
        "            frames,\n",
        "            1,\n",
        "            torch.linspace(\n",
        "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
        "            ).long(),\n",
        "        )\n",
        "        frame_list = [slow_pathway, fast_pathway]\n",
        "        return frame_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GA60fa3zWDQw"
      },
      "outputs": [],
      "source": [
        "transform =  ApplyTransformToKey(\n",
        "    key=\"video\",\n",
        "    transform=Compose(\n",
        "        [\n",
        "            UniformTemporalSubsample(num_frames),\n",
        "            Lambda(lambda x: x/255.0),\n",
        "            NormalizeVideo(mean, std),\n",
        "            ShortSideScale(\n",
        "                size=side_size\n",
        "            ),\n",
        "            CenterCropVideo(crop_size),\n",
        "            PackPathway()\n",
        "        ]\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pkqCNLzfWD1C"
      },
      "outputs": [],
      "source": [
        "def get_video_interval(video_path, start_sec, clip_duration):\n",
        "    end_sec = start_sec + clip_duration\n",
        "\n",
        "    video = EncodedVideo.from_path(video_path)\n",
        "\n",
        "    video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "    video_data = transform(video_data)\n",
        "\n",
        "    inputs = video_data[\"video\"]\n",
        "    inputs = [i.to(device)[None, ...] for i in inputs]\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xZoJkcUUWEKA"
      },
      "outputs": [],
      "source": [
        "def predict(inputs):\n",
        "    with torch.no_grad():\n",
        "        preds = sf_model(inputs)\n",
        "\n",
        "    post_act = torch.nn.Softmax(dim=1)\n",
        "    action_id = preds.argmax(dim=1).item()\n",
        "\n",
        "    return kinetics_id_to_classname[action_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "ZQImHXwaWEb9",
        "outputId": "588eefb3-a167-4361-eac0-ccee788dc32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 8, 256, 256])\n",
            "torch.Size([1, 3, 32, 256, 256])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'clean and jerk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "start_sec = 0\n",
        "interval = get_video_interval('source_video.mp4', start_sec, clip_duration)\n",
        "\n",
        "print(len(interval))\n",
        "print(interval[0].shape) # slow\n",
        "print(interval[1].shape) # fast\n",
        "\n",
        "predict(interval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNxiATqdWbvh",
        "outputId": "7db0b7a7-d4a3-445c-92c7-bd64c3670d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 s clean and jerk\n",
            "1 s clean and jerk\n",
            "2 s clean and jerk\n",
            "3 s clean and jerk\n",
            "4 s clean and jerk\n",
            "5 s clean and jerk\n",
            "6 s clean and jerk\n",
            "7 s clean and jerk\n",
            "8 s clean and jerk\n",
            "9 s clean and jerk\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    interval = get_video_interval('source_video.mp4', i, clip_duration)\n",
        "    pred = predict(interval)\n",
        "    print(i, 's', pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v6iJcpcqJb8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Xfu_ljofB4",
        "outputId": "0fddc296-2b26-472d-fb21-e360f5b646e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.4.7)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch<2.10,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.10,>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.10,>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV33PU-Yo1-w",
        "outputId": "5126224f-f178-40e8-eea2-053cbf067a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deep-sort-realtime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from deep-sort-realtime) (1.16.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from deep-sort-realtime) (4.12.0.88)\n"
          ]
        }
      ],
      "source": [
        "!pip install deep-sort-realtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BNUm2NfBn_EY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from collections import defaultdict, deque\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "yolo_model = YOLO(\"yolov8n.pt\")\n",
        "PERSON_CLASS_ID = 0"
      ],
      "metadata": {
        "id": "iJPF92wU9V3h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BRFStAMJwDhS"
      },
      "outputs": [],
      "source": [
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "tracker = DeepSort(\n",
        "    max_age=30,\n",
        "    n_init=3,\n",
        "    max_cosine_distance=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gpD2QeNUwDee"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "u8dCH_EUwDbd"
      },
      "outputs": [],
      "source": [
        "def preprocess_clip(frames_np):\n",
        "    frames = torch.from_numpy(frames_np)\n",
        "    frames = frames.permute(3, 0, 1, 2)\n",
        "    frames = frames.float()\n",
        "\n",
        "    video_data = {\"video\": frames}\n",
        "    video_data = transform(video_data)\n",
        "    inputs = video_data[\"video\"]\n",
        "\n",
        "    inputs = [i.unsqueeze(0).to(device) for i in inputs]\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4zNY9_hpwDYL"
      },
      "outputs": [],
      "source": [
        "def predict_clip(frames):\n",
        "    inputs = preprocess_clip(frames)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = sf_model(inputs)\n",
        "\n",
        "    action_id = preds.argmax(dim=1).item()\n",
        "\n",
        "    return kinetics_id_to_classname[action_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "imXLwh0NwDVm"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, deque\n",
        "\n",
        "clip_buffers = defaultdict(lambda: deque(maxlen=32))\n",
        "action_labels = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3xB48cqfwDTA"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(source_video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []"
      ],
      "metadata": {
        "id": "2luGpQ94H_WY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8477a3a7bd364602a2e808766f9eb538",
            "a72b7c78c7e549d58acec92eb3d045ac",
            "2e9f3e47abfe44e0a9d742ef7d5e1190",
            "2e2e9516f18a45cbb60d9e5467eb4586",
            "d1f6a26dbfdd45119185dc231638162d",
            "42b1011f4da4486496929b089b6fbd17",
            "84ba17383d0443e1a555f30b51f8609c",
            "17a7baed144c4005a63027ce21c7e5ae",
            "807402de0857441fa16ce0bd3e6239c4",
            "4ea899f946f6488c8b068ec15941e287",
            "b05375572d384f5b92203b3ec99b9aa7"
          ]
        },
        "id": "-B7Ho5phwDP7",
        "outputId": "6c6a6ac2-e3e1-4c35-ad6e-1c61b214831b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8477a3a7bd364602a2e808766f9eb538"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "frame_index = 0\n",
        "pbar = tqdm(total=300)\n",
        "\n",
        "while cap.isOpened():\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    MIN_BOX_AREA_RATIO = 0.1\n",
        "    frame_area = frame.shape[0] * frame.shape[1]\n",
        "\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    results = yolo_model(rgb, verbose=False)[0]\n",
        "    detections = []\n",
        "\n",
        "    for box in results.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "\n",
        "        if cls_id != PERSON_CLASS_ID:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "        area = w * h\n",
        "\n",
        "        if area < MIN_BOX_AREA_RATIO * frame_area:\n",
        "            continue\n",
        "\n",
        "        conf = float(box.conf[0])\n",
        "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
        "\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "\n",
        "        track_id = track.track_id\n",
        "        l, t, r, b = track.to_ltrb()\n",
        "        l, t, r, b = map(int, [l, t, r, b])\n",
        "\n",
        "        person_crop = rgb[t:b, l:r]\n",
        "        if person_crop.size == 0:\n",
        "            continue\n",
        "\n",
        "        person_crop = cv2.resize(person_crop, (256, 256))\n",
        "        clip_buffers[track_id].append(person_crop)\n",
        "\n",
        "        if len(clip_buffers[track_id]) == 32 and frame_index % 8 == 0:\n",
        "            clip = np.array(clip_buffers[track_id])\n",
        "            action = predict_clip(clip)\n",
        "            action_labels[track_id] = action\n",
        "\n",
        "        label = action_labels.get(track_id, \"...\")\n",
        "\n",
        "        labels.append(label)\n",
        "\n",
        "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID {track_id}: {label}\",\n",
        "                    (l, t - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "    frame_index += 1\n",
        "    pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "pbar.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "label_counts = Counter(labels)\n",
        "label_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVdXaZx-_XLB",
        "outputId": "c618164a-06f3-4662-aa00-706498a0c842"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'...': 33,\n",
              "         'vault': 68,\n",
              "         'playing trumpet': 48,\n",
              "         'gymnastics tumbling': 8,\n",
              "         'situp': 16,\n",
              "         'headbutting': 8,\n",
              "         'playing keyboard': 16,\n",
              "         'waxing legs': 8,\n",
              "         'lunge': 48,\n",
              "         'clean and jerk': 40})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8477a3a7bd364602a2e808766f9eb538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a72b7c78c7e549d58acec92eb3d045ac",
              "IPY_MODEL_2e9f3e47abfe44e0a9d742ef7d5e1190",
              "IPY_MODEL_2e2e9516f18a45cbb60d9e5467eb4586"
            ],
            "layout": "IPY_MODEL_d1f6a26dbfdd45119185dc231638162d"
          }
        },
        "a72b7c78c7e549d58acec92eb3d045ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b1011f4da4486496929b089b6fbd17",
            "placeholder": "​",
            "style": "IPY_MODEL_84ba17383d0443e1a555f30b51f8609c",
            "value": "100%"
          }
        },
        "2e9f3e47abfe44e0a9d742ef7d5e1190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a7baed144c4005a63027ce21c7e5ae",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_807402de0857441fa16ce0bd3e6239c4",
            "value": 300
          }
        },
        "2e2e9516f18a45cbb60d9e5467eb4586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea899f946f6488c8b068ec15941e287",
            "placeholder": "​",
            "style": "IPY_MODEL_b05375572d384f5b92203b3ec99b9aa7",
            "value": " 300/300 [03:47&lt;00:00,  1.21it/s]"
          }
        },
        "d1f6a26dbfdd45119185dc231638162d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b1011f4da4486496929b089b6fbd17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ba17383d0443e1a555f30b51f8609c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a7baed144c4005a63027ce21c7e5ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "807402de0857441fa16ce0bd3e6239c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ea899f946f6488c8b068ec15941e287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b05375572d384f5b92203b3ec99b9aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}